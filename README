###usage

perl Ancestry_HMM_parallel_v4.pl hmm_configuration_file.cfg

###set parameters in configuration file:
###See below for details on each parameter

hmm_configuration_file.cfg

###In the configuration file, give absolute paths from the directory where the jobs are submitted in the configuration file
##for example:

./example/genome1.fa

#instead of:

genome1.fa

###The coordinates from genome1 are used as the coordinates in the HMM so this should be the better assembled genome if there are substantial differences in reference quality.

###the full path is also needed in the reads list, and that list needs to be in the directory where the analysis is being run 

###WARNING:
if you provide an AIMs file and parental count file in the configuration file, these files must be in the same order and contain exactly the same sites. Coordinates given in these files must match the provided genomes. See swordtail examples for file format.

The AIMs file *must* be provided if the genomes are non-colinear. Otherwise the program will define them using the provided fasta files.

NOTE: The genome1 fasta file cannot contain _ in the chromosome names, this will be fixed in subsequent version. For now these can be replaced with - using i.e.: perl -pi -e 's/_/-/g' genome1.fa

###############
###DEPENDENCIES:
###############

###depends on the following programs that most clusters will already have installed:
##bwa ~(v0.7.15)
##samtools ~(v1.3.1)
##bcftools ~(1.3.1)

###depends on the following packages/libraries that will probably not already be installed
##armadillo #wget http://sourceforge.net/projects/arma/files/armadillo-7.960.0.tar.xz
##gperftools #git clone https://github.com/gperftools/gperftools.git
##ngsutils #git clone git://github.com/ngsutils/ngsutils.git
##Ancestry_HMM # git clone https://github.com/russcd/Ancestry_HMM.git
###NOTE: Ancestry_HMM will not install properly without armadillo and gperftools

##to test whether the pipeline will have required dependencies before running, go to the folder where you will submit the job and type:

bwa
samtools
bcftools
bamutils

#if all of these print the usage, then you are good to go!

ancestry_hmm

#for this command, it will not print usage, but if it prints: 

reading command line
ERROR: must provide input file
-i [path/to/input_file]

#it is installed properly

####################
###Parameter details
####################

#full path to the parental genomes
genome1=
genome2=

#read type, options are SE or PE
read_type=

#list containing full path to the reads, with PE reads tab separated on the same line
read_list=

#read length
read_length=

#proportion of the genome expected to be derived from the parent 1 species
prop_genome_genome1_parent=

#number of individuals to run in each job
number_indiv_per_job=

#Aims file listing the chromosome, position, parent 1 base, and parent 2 base,  see swordtail examples for format
provide_AIMs=

#Custom counts and recombination rate file. Format is chromosome, position, counts allele 1 in parent species 1, counts allele 2 in parent species 1, counts allele 1 in parent species 2, counts allele 2 in parent species 2, recombination rate in Morgans from previous marker
#if blank assumes fixed markers and a uniform recombination rate of 2e-08 Morgans per basepair
provide_counts=

#per base error parameter for HMM, if blank assumes zero
per_site_error=

#expected generations since initial admixture, if blank HMM estimates
gen_initial_admix=

#list of chromosomes to run the HMM on, can be useful for big genomes/sample sizes. List with one chromosome name per line
focal_chrom_list=

#maximum number of alignments to use. This is useful for pipeline spead/memory if there are some samples with lots of reads. If blank all reads are used
max_alignments=

#keep intermediate files, 0=no, 1=yes
retain_intermediate_files=

#slurm commands for each job
slurm_command_map=
slurm_command_variant_call=
slurm_command_hmm=
